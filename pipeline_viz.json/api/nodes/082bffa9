{
  "code": "def split_data(\n    prepared_data: pd.DataFrame,\n    params: Dict,\n) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Split prepared full DataFrame into train/test full DataFrames.\n\n    Returns train_dataset, test_dataset (each including features + target column).\n    Target is assumed to be the last column (consistent with previous logic).\n    \"\"\"\n    logger.info(\"Starting data splitting (full DataFrames) for model training\")\n    test_size = params.get(\"test_size\", 0.2)\n    random_state = params.get(\"random_state\", 42)\n    train_df, test_df = train_test_split(\n        prepared_data, test_size=test_size, random_state=random_state\n    )\n    logger.info(\"Full train rows=%d, test rows=%d\", len(train_df), len(test_df))\n    return train_df, test_df\n",
  "filepath": "kedropipe/src/modelcreation/pipelines/model_training/nodes.py",
  "parameters": {
    "model_training": {
      "test_size": 0.2,
      "random_state": 42,
      "old_model_column": "prediction_B",
      "loss_function": "Poisson",
      "iterations": 1000,
      "learning_rate": 0.1,
      "depth": 6,
      "early_stopping_rounds": 100,
      "verbose": 100,
      "mlflow_experiment_id": null,
      "mlflow_experiment_name": null
    }
  },
  "run_command": "kedro run --to-nodes='split_full_data_node'",
  "inputs": [
    "prepared_model_data",
    "params:model_training"
  ],
  "outputs": [
    "train_dataset",
    "test_dataset"
  ]
}