{
  "code": "def train_catboost_model(\n    X_train: pd.DataFrame,\n    X_test: pd.DataFrame, \n    y_train_str: str,\n    y_test_str: str,\n    feature_columns_str: str,\n    params: Dict\n) -> Tuple[str, str]:\n    \"\"\"Train a CatBoost model with Poisson loss and log to MLflow.\n    \n    Args:\n        X_train: Training features\n        X_test: Test features\n        y_train_str: Training target as CSV string\n        y_test_str: Test target as CSV string\n        feature_columns_str: Comma-separated feature column names\n        params: Parameters from conf/base/parameters.yml containing:\n            - loss_function: Loss function to use (default: Poisson)\n            - iterations: Number of boosting iterations\n            - learning_rate: Learning rate\n            - depth: Tree depth\n            - early_stopping_rounds: Early stopping patience\n            - verbose: Verbosity level\n        \n    Returns:\n        Tuple of:\n        - Trained CatBoost model as string (serialized)\n        - Dictionary of model metrics as string\n    \"\"\"\n    logger.info(\"Starting CatBoost model training\")\n    \n    # Convert text inputs back to pandas Series\n    import io\n    y_train = pd.read_csv(io.StringIO(y_train_str)).iloc[:, 0]\n    y_test = pd.read_csv(io.StringIO(y_test_str)).iloc[:, 0]\n    \n    # Parse feature columns\n    feature_columns = feature_columns_str.split(',')\n    logger.info(f\"Feature columns: {feature_columns}\")\n    \n    # Get model parameters\n    loss_function = params.get(\"loss_function\", \"Poisson\")\n    iterations = params.get(\"iterations\", 1000)\n    learning_rate = params.get(\"learning_rate\", 0.1)\n    depth = params.get(\"depth\", 6)\n    early_stopping_rounds = params.get(\"early_stopping_rounds\", 100)\n    verbose = params.get(\"verbose\", 100)\n    random_state = params.get(\"random_state\", 42)\n    \n    logger.info(\"Model parameters:\")\n    logger.info(f\"  Loss function: {loss_function}\")\n    logger.info(f\"  Iterations: {iterations}\")\n    logger.info(f\"  Learning rate: {learning_rate}\")\n    logger.info(f\"  Depth: {depth}\")\n    logger.info(f\"  Early stopping rounds: {early_stopping_rounds}\")\n    \n    # Setup MLflow experiment\n    experiment_id = setup_mlflow_experiment(params)\n    logger.info(f\"Using MLflow experiment ID: {experiment_id}\")\n    \n    # End any existing active run before starting training run\n    if mlflow.active_run():\n        try:\n            mlflow.end_run()\n        except Exception as exc:\n            logger.debug(\"Could not end pre-existing MLflow run: %s\", exc)\n    \n    # Start MLflow run\n    with mlflow.start_run(run_name=\"catboost_training\"):\n        # Log parameters\n        mlflow.log_param(\"loss_function\", loss_function)\n        mlflow.log_param(\"iterations\", iterations)\n        mlflow.log_param(\"learning_rate\", learning_rate)\n        mlflow.log_param(\"depth\", depth)\n        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n        mlflow.log_param(\"random_state\", random_state)\n        mlflow.log_param(\"train_size\", len(X_train))\n        mlflow.log_param(\"test_size\", len(X_test))\n        \n        # Initialize CatBoost model\n        model = CatBoostRegressor(\n            loss_function=loss_function,\n            iterations=iterations,\n            learning_rate=learning_rate,\n            depth=depth,\n            early_stopping_rounds=early_stopping_rounds,\n            verbose=verbose,\n            random_state=random_state,\n            train_dir=None  # Disable training directory to avoid clutter\n        )\n        \n        # Train the model\n        logger.info(\"Training CatBoost model...\")\n        model.fit(\n            X_train, y_train,\n            eval_set=(X_test, y_test),\n            use_best_model=True,\n            plot=False\n        )\n        \n        # Make predictions\n        logger.info(\"Making predictions...\")\n        y_train_pred = model.predict(X_train)\n        y_test_pred = model.predict(X_test)\n        \n        # Calculate metrics\n        train_mae = mean_absolute_error(y_train, y_train_pred)\n        test_mae = mean_absolute_error(y_test, y_test_pred)\n        train_rmse = (mean_squared_error(y_train, y_train_pred)) ** 0.5\n        test_rmse = (mean_squared_error(y_test, y_test_pred)) ** 0.5\n        \n        # Log metrics to MLflow\n        mlflow.log_metric(\"train_mae\", train_mae)\n        mlflow.log_metric(\"test_mae\", test_mae)\n        mlflow.log_metric(\"train_rmse\", train_rmse)\n        mlflow.log_metric(\"test_rmse\", test_rmse)\n        mlflow.log_metric(\"best_iteration\", model.best_iteration_)\n        \n        # Get feature importance\n        feature_importance = dict(zip(feature_columns, model.feature_importances_))\n        \n        # Log feature importance as metrics\n        for feature, importance in feature_importance.items():\n            mlflow.log_metric(f\"feature_importance_{feature}\", importance)\n        \n        # Log the model to MLflow\n        mlflow.catboost.log_model(\n            model, \n            \"catboost_model\"\n        )\n        \n        # Store the run ID for later retrieval\n        run_id = mlflow.active_run().info.run_id\n        logger.info(f\"MLflow run ID: {run_id}\")\n        \n        # Compile metrics\n        metrics = {\n            \"train_mae\": train_mae,\n            \"test_mae\": test_mae,\n            \"train_rmse\": train_rmse,\n            \"test_rmse\": test_rmse,\n            \"best_iteration\": model.best_iteration_,\n            \"feature_importance\": feature_importance,\n            \"mlflow_run_id\": run_id,\n            \"model_params\": {\n                \"loss_function\": loss_function,\n                \"iterations\": iterations,\n                \"learning_rate\": learning_rate,\n                \"depth\": depth,\n                \"best_iteration\": model.best_iteration_\n            }\n        }\n        \n        logger.info(\"Model training completed!\")\n        logger.info(f\"Best iteration: {model.best_iteration_}\")\n        logger.info(f\"Training MAE: {train_mae:.4f}\")\n        logger.info(f\"Test MAE: {test_mae:.4f}\")\n        logger.info(f\"Training RMSE: {train_rmse:.4f}\")\n        logger.info(f\"Test RMSE: {test_rmse:.4f}\")\n        logger.info(f\"MLflow run ID: {run_id}\")\n        \n        logger.info(\"Feature importance:\")\n        for feature, importance in sorted(feature_importance.items(), key=lambda x: x[1], reverse=True):\n            logger.info(f\"  {feature}: {importance:.4f}\")\n        \n        # Return the actual model object and metrics as JSON string\n        import json\n        metrics_str = json.dumps(metrics, indent=2)\n        \n        return model, metrics_str\n",
  "filepath": "kedropipe/src/modelcreation/pipelines/model_training/nodes.py",
  "parameters": {
    "model_training": {
      "test_size": 0.2,
      "random_state": 42,
      "old_model_column": "prediction_B",
      "loss_function": "Poisson",
      "iterations": 1000,
      "learning_rate": 0.1,
      "depth": 6,
      "early_stopping_rounds": 100,
      "verbose": 100,
      "mlflow_experiment_id": null,
      "mlflow_experiment_name": null
    }
  },
  "run_command": "kedro run --to-nodes='train_catboost_model_node'",
  "inputs": [
    "X_train",
    "X_test",
    "y_train",
    "y_test",
    "feature_columns",
    "params:model_training"
  ],
  "outputs": [
    "trained_model",
    "model_metrics"
  ]
}