{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddfb5d7",
   "metadata": {},
   "source": [
    "# Model Monitoring KPI Example\n",
    "This notebook demonstrates how to use the `predlab` module to define and analyze Key Performance Indicators (KPIs) across different data segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f1f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from predlab import (\n",
    "    SegmentCustom,\n",
    ")\n",
    "\n",
    "# Import the new model analyses builder\n",
    "from predlab.model_analyses import ModelAnalysisDataBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1802f8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predlab file: /home/diego/Dropbox/DropboxGit/VarTester/src/predlab/__init__.py\n",
      "has compute_percentile_bins: True\n",
      "SegmentCustom has round_bounds: True\n",
      "apply uses percentile: True\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "import predlab\n",
    "\n",
    "print(\"predlab file:\", predlab.__file__)\n",
    "try:\n",
    "    import predlab.segmentation as seg\n",
    "\n",
    "    print(\"has compute_percentile_bins:\", hasattr(seg, \"compute_percentile_bins\"))\n",
    "    print(\n",
    "        \"SegmentCustom has round_bounds:\",\n",
    "        \"round_bounds\" in str(inspect.signature(seg.SegmentCustom.__init__)),\n",
    "    )\n",
    "    print(\n",
    "        \"apply uses percentile:\",\n",
    "        \"compute_percentile_bins\" in inspect.getsource(seg.SegmentCustom.apply),\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"segmentation import/inspect error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4c5e1",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "First, we'll create a synthetic dataset. This dataset mimics a typical insurance scenario with multiple coverages, predictions (risk premiums), and observed outcomes (targets/claims). The data is saved to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d967d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data generated and saved to ../../data/segmentation_data_comp.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>market_premium</th>\n",
       "      <th>region</th>\n",
       "      <th>prediction_A</th>\n",
       "      <th>prediction_A_comp</th>\n",
       "      <th>target_A</th>\n",
       "      <th>prediction_B</th>\n",
       "      <th>prediction_B_comp</th>\n",
       "      <th>target_B</th>\n",
       "      <th>prediction_C</th>\n",
       "      <th>prediction_C_comp</th>\n",
       "      <th>target_C</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>31626.419807</td>\n",
       "      <td>693</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>West</td>\n",
       "      <td>0.097585</td>\n",
       "      <td>0.125872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091178</td>\n",
       "      <td>0.115140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087754</td>\n",
       "      <td>0.108845</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>94350.676790</td>\n",
       "      <td>565</td>\n",
       "      <td>0.230289</td>\n",
       "      <td>East</td>\n",
       "      <td>0.393303</td>\n",
       "      <td>0.538192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346978</td>\n",
       "      <td>0.462553</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317891</td>\n",
       "      <td>0.414508</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>34226.773664</td>\n",
       "      <td>803</td>\n",
       "      <td>0.112133</td>\n",
       "      <td>South</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.064002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>0.061465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>189107.488476</td>\n",
       "      <td>433</td>\n",
       "      <td>0.410269</td>\n",
       "      <td>North</td>\n",
       "      <td>0.220123</td>\n",
       "      <td>0.254587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>0.253137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>0.256432</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>32588.089714</td>\n",
       "      <td>325</td>\n",
       "      <td>0.305161</td>\n",
       "      <td>South</td>\n",
       "      <td>0.230528</td>\n",
       "      <td>0.302809</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207231</td>\n",
       "      <td>0.266090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192646</td>\n",
       "      <td>0.242651</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         income  credit_score  market_premium region  prediction_A  \\\n",
       "0   56   31626.419807           693        0.295256   West      0.097585   \n",
       "1   69   94350.676790           565        0.230289   East      0.393303   \n",
       "2   46   34226.773664           803        0.112133  South      0.051926   \n",
       "3   32  189107.488476           433        0.410269  North      0.220123   \n",
       "4   60   32588.089714           325        0.305161  South      0.230528   \n",
       "\n",
       "   prediction_A_comp  target_A  prediction_B  prediction_B_comp  target_B  \\\n",
       "0           0.125872         0      0.091178           0.115140         0   \n",
       "1           0.538192         0      0.346978           0.462553         1   \n",
       "2           0.064002         0      0.050744           0.061465         0   \n",
       "3           0.254587         0      0.221539           0.253137         0   \n",
       "4           0.302809         0      0.207231           0.266090         0   \n",
       "\n",
       "   prediction_C  prediction_C_comp  target_C  weight  \n",
       "0      0.087754           0.108845         0     1.0  \n",
       "1      0.317891           0.414508         0     1.0  \n",
       "2      0.050761           0.060585         0     1.0  \n",
       "3      0.226736           0.256432         1     1.0  \n",
       "4      0.192646           0.242651         0     1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Create a Synthetic Dataset ---\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Create some numerical features\n",
    "features = pd.DataFrame(\n",
    "    {\n",
    "        \"age\": np.random.randint(18, 70, n_samples),\n",
    "        \"income\": np.random.gamma(2, 40000, n_samples),\n",
    "        \"credit_score\": np.random.randint(300, 850, n_samples),\n",
    "        \"market_premium\": np.random.uniform(0.1, 0.5, n_samples),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a categorical feature\n",
    "features[\"region\"] = np.random.choice(\n",
    "    [\"North\", \"South\", \"East\", \"West\"], n_samples, p=[0.3, 0.2, 0.25, 0.25]\n",
    ")\n",
    "\n",
    "# --- Generate data for N=3 coverages in a wide format ---\n",
    "N_coverages = 3\n",
    "df = features.copy()\n",
    "\n",
    "for i in range(N_coverages):\n",
    "    cov_suffix = f\"_{chr(65 + i)}\"  # e.g., _A, _B, _C\n",
    "\n",
    "    # --- Generate True Risk (rate for Poisson) ---\n",
    "    true_risk_formula = (\n",
    "        -4.0\n",
    "        + (i * 0.1)\n",
    "        + df[\"age\"] / (20 + i * 2)\n",
    "        - df[\"credit_score\"] / (500 + i * 20)\n",
    "        + df[\"income\"] / 100000\n",
    "    )\n",
    "    true_risk_index = np.exp(true_risk_formula)\n",
    "\n",
    "    # --- Generate a Slightly Incorrect Prediction ---\n",
    "    prediction_formula = (\n",
    "        -3.9\n",
    "        + (i * 0.1)\n",
    "        + df[\"age\"] / (22 + i * 2)\n",
    "        - df[\"credit_score\"] / (550 + i * 20)\n",
    "        + df[\"income\"] / 110000\n",
    "    )\n",
    "    df[f\"prediction{cov_suffix}\"] = np.exp(prediction_formula)\n",
    "    df[f\"prediction{cov_suffix}_comp\"] = np.exp(\n",
    "        prediction_formula + 0.1 * +df[\"age\"] / (22 + i * 2)\n",
    "    )\n",
    "    # --- Generate Target (claims) from the true risk ---\n",
    "    df[f\"target{cov_suffix}\"] = np.random.poisson(true_risk_index)\n",
    "\n",
    "# Add a single weight column\n",
    "df[\"weight\"] = 1.0\n",
    "\n",
    "# Save to parquet\n",
    "output_path = \"../../data/segmentation_data_comp.parquet\"\n",
    "df.to_parquet(output_path)\n",
    "\n",
    "print(f\"Synthetic data generated and saved to {output_path}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a52745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9188294\ttotal: 50ms\tremaining: 9.95s\n",
      "50:\tlearn: 0.3913641\ttotal: 252ms\tremaining: 736ms\n",
      "100:\tlearn: 0.3766409\ttotal: 419ms\tremaining: 411ms\n",
      "150:\tlearn: 0.3725671\ttotal: 640ms\tremaining: 208ms\n",
      "199:\tlearn: 0.3690083\ttotal: 798ms\tremaining: 0us\n",
      "CatBoost model training complete.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Define features and target\n",
    "feature_cols = [\"age\", \"income\", \"credit_score\"]\n",
    "target_col = \"target_A\"\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Initialize and train the CatBoost Regressor model\n",
    "# Using some default parameters for this example\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=200,\n",
    "    learning_rate=0.05,\n",
    "    depth=5,\n",
    "    verbose=50,\n",
    "    loss_function=\"Poisson\",\n",
    ")\n",
    "\n",
    "cat_model.fit(X, y)\n",
    "\n",
    "print(\"CatBoost model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a2b62",
   "metadata": {},
   "source": [
    "## 2. Configure the Analysis\n",
    "\n",
    "Now, we set up the analysis by defining the coverages, segmentation strategies, and data treatments.\n",
    "\n",
    "### Prediction & Target Mapping\n",
    "We create a dictionary to map each coverage to its corresponding prediction, target, and weight columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f81a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {\n",
    "    \"A\": {\"sel_col\": \"weight\", \"pred_col\": \"prediction_A\", \"target_col\": \"target_A\"},\n",
    "    \"B\": {\"sel_col\": \"weight\", \"pred_col\": \"prediction_B\", \"target_col\": \"target_B\"},\n",
    "    \"C\": {\"sel_col\": \"weight\", \"pred_col\": \"prediction_C\", \"target_col\": \"target_C\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c7039",
   "metadata": {},
   "source": [
    "### Segmentation Strategies\n",
    "We define how to segment the data. We can create segments from categorical features or by binning numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84d18a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 segments defined.\n"
     ]
    }
   ],
   "source": [
    "segments = [\n",
    "    # Segment for Age with custom bins\n",
    "    SegmentCustom(\n",
    "        seg_col=\"age\",\n",
    "        seg_name=\"age_group\",\n",
    "        bins=[18, 30, 45, 60, 75],\n",
    "        bin_labels=[\"18-29\", \"30-44\", \"45-59\", \"60+\"],\n",
    "    ),\n",
    "    # Segment for Income with 5 equal-width bins\n",
    "    SegmentCustom(seg_col=\"income\", seg_name=\"income_level\", bins=5),\n",
    "    # Segment for Credit Score (binned)\n",
    "    SegmentCustom(seg_col=\"credit_score\", seg_name=\"credit_score_level\", bins=5),\n",
    "]\n",
    "print(f\"{len(segments)} segments defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150be90f",
   "metadata": {},
   "source": [
    "### Initialize Analysis and Apply Treatments\n",
    "We initialize the `AnalysisDataBuilder` object, which orchestrates the data loading, treatment, and segmentation. Treatments are applied to the data, such as iso resources scaling of predictions or aggregating totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60755785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a configuration dict for model analysis (PDP)\n",
    "func_dict_pdp = {\n",
    "    \"model\": {\n",
    "        \"model\": cat_model,\n",
    "        \"name\": \"model A\",\n",
    "        # Provide feature_cols explicitly so PDP knows input layout\n",
    "        \"feature_cols\": [\"age\", \"income\", \"credit_score\"],\n",
    "    },\n",
    "    # Optional global weight/target\n",
    "    \"target_col\": \"target_A\",\n",
    "    \"weight_col\": \"weight\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ceabcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelAnalysisDataBuilder with the data path\n",
    "lr_analysis = ModelAnalysisDataBuilder(\n",
    "    data=output_path, extra_cols=[\"market_premium\"]\n",
    ")  # extra_cols optional here\n",
    "\n",
    "# Register analyses\n",
    "lr_analysis.add_analysis(\"PDP\", func_dict_pdp)\n",
    "\n",
    "# Add segments (used to derive PDP grids for the corresponding features)\n",
    "for s in segments:\n",
    "    lr_analysis.add_segment(s)\n",
    "\n",
    "# Load data\n",
    "lr_analysis.load_data()\n",
    "\n",
    "# Calculate all\n",
    "lr_analysis.calculate()\n",
    "\n",
    "# Collect analysis objects\n",
    "analyses_objs = lr_analysis.get_analyses_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45400f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB columns (income-related): ['income']\n",
      "income_level not found in DB\n"
     ]
    }
   ],
   "source": [
    "# Inspect DB after calculation\n",
    "cols = [c for c in lr_analysis.db.columns if \"income\" in c or \"level\" in c]\n",
    "print(\"DB columns (income-related):\", cols)\n",
    "if \"income_level\" in lr_analysis.db.columns:\n",
    "    s = lr_analysis.db[\"income_level\"]\n",
    "    print(\"dtype:\", s.dtype)\n",
    "    try:\n",
    "        cats = list(s.dtype.categories[:5])\n",
    "        print(\"categories sample:\", cats)\n",
    "        print(\"category type:\", type(cats[0]))\n",
    "    except Exception as e:\n",
    "        print(\"no categories or error:\", e)\n",
    "    print(\"value sample:\", s.astype(str).head().tolist())\n",
    "else:\n",
    "    print(\"income_level not found in DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7daf7e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>bin</th>\n",
       "      <th>eval_value</th>\n",
       "      <th>prediction</th>\n",
       "      <th>pdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_group</td>\n",
       "      <td>18-29</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.051606</td>\n",
       "      <td>0.051606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age_group</td>\n",
       "      <td>30-44</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.105462</td>\n",
       "      <td>0.105462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_group</td>\n",
       "      <td>45-59</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.226281</td>\n",
       "      <td>0.226281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_group</td>\n",
       "      <td>60+</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.463256</td>\n",
       "      <td>0.463256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>income_level</td>\n",
       "      <td>[221, 33200)</td>\n",
       "      <td>16698.653094</td>\n",
       "      <td>0.085380</td>\n",
       "      <td>0.085380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>income_level</td>\n",
       "      <td>[33200, 54800)</td>\n",
       "      <td>44009.225526</td>\n",
       "      <td>0.111193</td>\n",
       "      <td>0.111193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>income_level</td>\n",
       "      <td>[54800, 80300)</td>\n",
       "      <td>67586.423705</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>income_level</td>\n",
       "      <td>[80300, 121000)</td>\n",
       "      <td>100652.244478</td>\n",
       "      <td>0.195735</td>\n",
       "      <td>0.195735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>income_level</td>\n",
       "      <td>[121000, 548000)</td>\n",
       "      <td>334380.032911</td>\n",
       "      <td>3.031624</td>\n",
       "      <td>3.031624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>credit_score_level</td>\n",
       "      <td>[300, 409)</td>\n",
       "      <td>354.500000</td>\n",
       "      <td>0.286290</td>\n",
       "      <td>0.286290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>credit_score_level</td>\n",
       "      <td>[409, 522)</td>\n",
       "      <td>465.500000</td>\n",
       "      <td>0.239470</td>\n",
       "      <td>0.239470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit_score_level</td>\n",
       "      <td>[522, 631)</td>\n",
       "      <td>576.500000</td>\n",
       "      <td>0.189028</td>\n",
       "      <td>0.189028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>credit_score_level</td>\n",
       "      <td>[631, 740)</td>\n",
       "      <td>685.500000</td>\n",
       "      <td>0.154376</td>\n",
       "      <td>0.154376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>credit_score_level</td>\n",
       "      <td>[740, 849)</td>\n",
       "      <td>794.500000</td>\n",
       "      <td>0.122919</td>\n",
       "      <td>0.122919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               segment               bin     eval_value  prediction       pdp\n",
       "0            age_group             18-29      24.000000    0.051606  0.051606\n",
       "1            age_group             30-44      37.500000    0.105462  0.105462\n",
       "2            age_group             45-59      52.500000    0.226281  0.226281\n",
       "3            age_group               60+      67.500000    0.463256  0.463256\n",
       "4         income_level      [221, 33200)   16698.653094    0.085380  0.085380\n",
       "5         income_level    [33200, 54800)   44009.225526    0.111193  0.111193\n",
       "6         income_level    [54800, 80300)   67586.423705    0.131100  0.131100\n",
       "7         income_level   [80300, 121000)  100652.244478    0.195735  0.195735\n",
       "8         income_level  [121000, 548000)  334380.032911    3.031624  3.031624\n",
       "9   credit_score_level        [300, 409)     354.500000    0.286290  0.286290\n",
       "10  credit_score_level        [409, 522)     465.500000    0.239470  0.239470\n",
       "11  credit_score_level        [522, 631)     576.500000    0.189028  0.189028\n",
       "12  credit_score_level        [631, 740)     685.500000    0.154376  0.154376\n",
       "13  credit_score_level        [740, 849)     794.500000    0.122919  0.122919"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyses_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "204bf185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique bins (income_level): ['[121000, 548000)', '[221, 33200)', '[33200, 54800)', '[54800, 80300)', '[80300, 121000)']\n"
     ]
    }
   ],
   "source": [
    "# Show unique bins for the income_level PDP to verify labels\n",
    "try:\n",
    "    bins_series = analyses_objs.loc[analyses_objs[\"segment\"] == \"income_level\", \"bin\"]\n",
    "    print(\"unique bins (income_level):\", sorted(set(bins_series.tolist()))[:8])\n",
    "except Exception as e:\n",
    "    print(\"Error extracting bins:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4381b1bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'income_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/DropboxGit/VarTester/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'income_level'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Debug: inspect the dtype and first categories of the income_level segment\u001b[39;00m\n\u001b[32m      2\u001b[39m seg_name = \u001b[33m'\u001b[39m\u001b[33mincome_level\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m raw = \u001b[43mlr_analysis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseg_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdtype:\u001b[39m\u001b[33m'\u001b[39m, raw.dtype)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/DropboxGit/VarTester/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/DropboxGit/VarTester/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'income_level'"
     ]
    }
   ],
   "source": [
    "# Debug: inspect the dtype and first categories of the income_level segment\n",
    "seg_name = \"income_level\"\n",
    "raw = lr_analysis.db[seg_name]\n",
    "print(\"dtype:\", raw.dtype)\n",
    "try:\n",
    "    cats = list(raw.dtype.categories[:5])\n",
    "    print(\"categories sample:\", cats)\n",
    "    print(\"category type:\", type(cats[0]))\n",
    "except Exception as e:\n",
    "    print(\"no categories or error:\", e)\n",
    "\n",
    "# Show unique values (limited)\n",
    "print(\"unique sample:\", list(pd.Series(raw).astype(str).unique())[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
