import pandas as pd

from .data_loader import DataFrameDataLoader, ParquetDataLoader, TripleParquetDataLoader
from .treatments import (
    TreatmentAddTotalCoverage,
    TreatmentColumnScaling,
    TreatmentIsoResourceScaling,
    TreatmentLeftJoin,
    TreatmentPairwiseIsoResourceScaling,
)

# Treatment registry for string-based instantiation
TREATMENT_REGISTRY = {
    "IsoResourceScaling": TreatmentIsoResourceScaling,
    "AddTotalCoverage": TreatmentAddTotalCoverage,
    "PairwiseIsoResourceScaling": TreatmentPairwiseIsoResourceScaling,
    "ColumnScaling": TreatmentColumnScaling,
    "LeftJoin": TreatmentLeftJoin,
}


class AnalysisDataBuilder:
    """AnalysisDataBuilder is a class for loading tabular data from a DataFrame, a single parquet file, or multiple parquet files,
    and for managing feature engineering via user-defined treatments and segmentations. It allows dynamic creation of new
    columns based on segmentation of existing columns or custom treatment logic, facilitating flexible data preparation
    for model monitoring and analysis.

    Attributes:
        data_loader: Loader object for the input data source.
        db: Internal pandas DataFrame holding the loaded and processed data.
        cols_to_get: List of columns to retrieve from the data source.
        treatements: List of treatment objects/functions to apply to the data.
        segments: List of segment objects for data segmentation.
        segments_names: Dictionary mapping segment names to their labels.
        metrics: Dictionary storing metrics generated by treatments.
        treatments_cols: List of columns created by treatments.

    Methods:
        add_col(c): Adds a column to the retrieval list if not already present.
        add_treatment(treatment, *args, **kwargs): Registers a treatment and its required/created columns.
                   Can accept either a treatment object or a string name from TREATMENT_REGISTRY.
        add_segment(seg): Registers a segment and its required columns.
        list_available_treatments(): Returns a list of available treatment names from the registry.
        load_data(): Loads data from the source, applying column selection.
        apply_treatments(): Applies all registered treatments to the data, updating metrics.
        apply_segments(): Applies all registered segments to the data.
        load_data(): Loads data from the source, applying column selection.
        apply_treatments(): Applies all registered treatments to the data, updating metrics.
        apply_segments(): Applies all registered segments to the data.
    """

    def __init__(self, extra_cols=None, treatements=None):
        """Initializes the AnalysisDataBuilder object.

        Args:
            extra_cols (list, optional): List of extra columns to load. Defaults to None.
            treatements (list, optional): List of treatment functions to apply to the data. Defaults to None.
        """
        if treatements is None:
            treatements = []

        self.data_loader = None
        self.db = None
        self.cols_to_get = extra_cols if extra_cols is not None else []
        self.treatements = treatements
        self.segments = []
        self.segments_names = {}
        self.metrics = {}
        self.treatments_cols = []

    def add_col(self, c):
        """Add a column to the list of columns to retrieve.

        Args:
            c: The column to add.
        """
        if c not in self.cols_to_get:
            self.cols_to_get.append(c)

    def add_treatment(self, treatment, *args, **kwargs):
        """Add a treatment to the monitor, updating columns and created columns.

        Args:
            treatment: Either a treatment object with methods get_cols() and get_created_cols(),
                      or a string name from TREATMENT_REGISTRY to instantiate the treatment.
            *args: Arguments to pass to the treatment constructor if treatment is a string.
            **kwargs: Keyword arguments to pass to the treatment constructor if treatment is a string.
        """
        # If treatment is a string, instantiate it from the registry
        if isinstance(treatment, str):
            if treatment not in TREATMENT_REGISTRY:
                available_treatments = list(TREATMENT_REGISTRY.keys())
                raise ValueError(
                    f"Treatment '{treatment}' not found in registry. "
                    f"Available treatments: {available_treatments}"
                )
            treatment_class = TREATMENT_REGISTRY[treatment]
            treatment = treatment_class(*args, **kwargs)

        self.treatements.append(treatment)
        for c in treatment.get_cols():
            self.add_col(c)
        self.treatments_cols.extend(treatment.get_created_cols())

    @staticmethod
    def list_available_treatments():
        """Returns a list of available treatment names from the registry.

        Returns:
            list: List of available treatment names that can be used with add_treatment().
        """
        return list(TREATMENT_REGISTRY.keys())

    def add_segment(self, seg):
        """Adds a segment to the monitoring object, updates segment names, and registers its columns.

        Args:
            seg: Segment object to be added.
        """
        self.segments.append(seg)
        self.segments_names[seg.seg_name] = seg.seg_label
        for c in seg.get_cols():
            self.add_col(c)

    def load_data(self, data=None):
        """Loads data from the source if it hasn't been loaded yet.

        Args:
            data (Union[str, pd.DataFrame, Dict], optional): The input data.
                                             - str: path to a single parquet file.
                                             - pd.DataFrame: pandas DataFrame.
                                             - Dict: arguments for TripleParquetDataLoader.
                                             If not provided, uses existing data_loader.
        """
        if data is not None:
            # Set up data loader if data is provided
            if isinstance(data, str):
                self.data_loader = ParquetDataLoader(data)
            elif isinstance(data, pd.DataFrame):
                self.data_loader = DataFrameDataLoader(data)
            elif isinstance(data, dict):
                self.data_loader = TripleParquetDataLoader(**data)
            else:
                raise TypeError(
                    "data must be a pandas DataFrame, a string path, or a dictionary for TripleParquetDataLoader."
                )

        if self.data_loader is None:
            raise ValueError(
                "No data source specified. Provide data either in __init__ or load_data() method."
            )

        if self.db is None:
            # Preserve order while filtering out treatment columns
            treatments_cols_set = set(self.treatments_cols)
            cols_to_load = [
                col for col in self.cols_to_get if col not in treatments_cols_set
            ]

            self.db = self.data_loader.load(
                columns=cols_to_load if cols_to_load else None
            )

    def apply_treatments(self):
        """Applies a sequence of treatment functions to the internal database.
        If the database is not loaded, it loads the data first. For each treatment in the `treatements` list,
        it applies the treatment to the current database, updates the database with the result, and merges any
        returned metrics into the internal metrics dictionary.

        Returns:
            None
        """
        if self.db is None:
            self.load_data()
        for t in self.treatements:
            # Assuming treatment functions return a dictionary with a 'db' key
            out = t.apply(self.db)
            self.db = out["db"]
            if "metrics" in out and isinstance(out["metrics"], dict):
                self.metrics.update(out["metrics"])

    def apply_segments(self):
        """Applies all defined segmentations to the DataFrame.
        If data is not loaded, it calls load_data() first.
        """
        if self.db is None:
            self.load_data()

        for seg in self.segments:
            seg.apply(self.db)

        return self.db
